{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"census analysis.ipynb","provenance":[],"authorship_tag":"ABX9TyMTNM+ZseVNDfr0iKFgjjKv"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"5QfConPm_6rM","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9C-crACdALwi","colab_type":"code","colab":{}},"source":["import os\n","data_dir = '/content/gdrive/My Drive/MLC/Session 1/Data/'\n","os.listdir(data_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b5SMdtCtTW5T","colab_type":"text"},"source":["We will start by loading the census data and viewing a few rows. Look at the values in this sample of rows and get an initial feel for what it contains."]},{"cell_type":"code","metadata":{"id":"mVfohDHvAYTo","colab_type":"code","colab":{}},"source":["import pandas as pd\n","census_data = pd.read_csv(data_dir + 'us_census_1994.txt', delimiter=\"\\t\")\n","census_data\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QKWp62sKaHj3","colab_type":"text"},"source":["Note: The fnlwgt ('Final Weight') column was deviced by the statisticians based on demographic population sizes. It turns out not to be useful for our machine learning task so you can ignore it for the purposes of this tutorial."]},{"cell_type":"markdown","metadata":{"id":"LiZBsVUkTmXH","colab_type":"text"},"source":["Next we run the describe command again and get summaries of the numerical columns.\n","Once again pay attention to max and min values but this time we will also examine the mean (average), and interquartile ranges (25%, 50%, 75%) too.\n","\n","**What do the min value for age tell you about this sample? Do you think America's oldest person is included? What is the average age? Do you think you can find someone in the dataset who is exactly average age?**\n","\n","**What do you think the max value of hoursperweek tells us about that column?**\n","\n","Interquartile ranges are a useful way to understand the distribution of the data. To calculate quartiles for a column we sort the data in numeric order (we don't actually have to do this, Python is doing that for us. Which is handy!). The 50% quartile is also known as the median and represents the midpoint of the data. So the age of the person right in the middle is 37 when we sort by age. Note this is different, but quite close to the mean.\n","\n","**Compare the 50% with the means of the other columns.**\n","\n","**What do you think the 75% point tells us about 'capital gain'?**\n","\n","**What do you think the 25% point tells us about 'hours per week'?**\n","\n","For more information on quartiles have a look at: https://www.mathsisfun.com/data/quartiles.html"]},{"cell_type":"code","metadata":{"id":"VQDEUVHMNqse","colab_type":"code","colab":{}},"source":["census_data.describe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IEWSW3X0bK8H","colab_type":"text"},"source":["If at any point you need a reminder of the column names in the dataset, just run this command:"]},{"cell_type":"code","metadata":{"id":"_5XVPtr1S-EF","colab_type":"code","colab":{}},"source":["census_data.columns"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2KFBKMnDbU_g","colab_type":"text"},"source":["We will now look at the salary column. When we come to machine learning this will be the column we try to predict: Given the values in all the other columns, does the person earn more than $50,000?\n","\n","The \"groupby\" function, combined with \"size\", gives us a count of rows per value in a column. Run this for the \"salary\" column.\n","\n","**Is the data evenly distributed?**"]},{"cell_type":"code","metadata":{"id":"GsZATBoUFjty","colab_type":"code","colab":{}},"source":["census_data.groupby(by=['salary']).size()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PTK4ZjSckGWX","colab_type":"text"},"source":["One useful way of exploring relationships between numerical columns is to use a 'pairs plot'. This plot creates a grid of graphs for selected columns. In this case we are colouring points or columns by salary (you can see in the legend on the right hand side which colour is which).\n","\n","The plot itself needs some explanation.\n","\n","There are 9 plots here. We will start with the 3 along the diagonal. These are graphs on the values for each attribute, starting with 'age' on the left which shows the distribution of ages in the dataset split by salary. The scale is at the bottom of the left hand column. **Where do the peaks lie for each salary group?**\n","\n","Compare the top left and bottom right plots. **Do they tell you the same thing about proportions of the two salary bands?**\n","\n","The remaining charts can be put in pairs. The bottom left has 'age' on the x-axis and 'educationnum' on the y-axis, while the top right has the same variables but swapped around. In other words if you flip the bottom left one around you will get the top right one. So you can ignore the graphs below (or above) the diagonal if you want to.\n","\n","These other charts can be used to spot correlations between columns. A correlation is when two variables move in tandem, as one goes up the other one goes up (or they can go down). **Do any of these variables look correlated?**\n","\n","Thinking about the Machine Learning task of prediction, **which of these variables would you use to \"Guess\" someone's salary?**"]},{"cell_type":"code","metadata":{"id":"BAtw3b56iaMe","colab_type":"code","colab":{}},"source":["# Pairs plot\n","import seaborn as sns\n","sns.pairplot(census_data[{'age','educationnum','capitalgain', 'salary'}], hue=\"salary\", kind='scatter', plot_kws={'alpha':0.5})"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qB5DwmuLcCvH","colab_type":"text"},"source":["For the remaining columns we can use grouping to create summary counts. This won't work so well for numerical columns where there are many values (especially if they have a decimal value, which we don't see in this dataset). In this case a graph would be better. But when we're dealing with 'categorical' values such as 'maritalstatus' it works well.\n","(Don't forget the columns function from above if you can't remember the column names)\n","\n","**What do you notice about the 'occupation' column?**\n","\n","**Are there other columns with the same issue?**\n","\n","**Is this a problem?**"]},{"cell_type":"code","metadata":{"id":"OtGVW_6oOie0","colab_type":"code","colab":{}},"source":["census_data.groupby(by=['maritalstatus']).size()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8VUWm2LEdltJ","colab_type":"text"},"source":["We can also use groupby to group two (or more) columns at a time.\n","\n","**What does the output of the next command tell us about 'educationnum' and 'education'?**"]},{"cell_type":"code","metadata":{"id":"KX_ZTfLqHTjr","colab_type":"code","colab":{}},"source":["census_data.groupby(by=['educationnum','education']).size()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hDzFtCwsd8Em","colab_type":"text"},"source":["This leads us to an important aspect of preparing data for Machine Learning. The majority of ML algorithms require numbers as input. Most of our columns are labels.\n","\n","Let's compare the 'education' column with 'workclass'. **Could you put both of them in an order of superiority?**\n","\n","**Could you assign a numeric value to 'education'?**\n","\n","**What about to workclass?**"]},{"cell_type":"markdown","metadata":{"id":"OYC3Dvt6fTs-","colab_type":"text"},"source":["One technique for converting categorical variables to numeric values is to use **'one hot encoding'**.\n","\n","This technique converts the values in a column to binary values by creating a new column per unique value in the column. We can do this with the 'get_dummies' function. Running this for the 'workclass' column returns a table with 9 columns, one for each unique value in the column. Compare with the output of the 'groupby' command above if you need reassurance.\n","\n","This hasn't added the columns to our census data yet. First we need to do something with the question marks."]},{"cell_type":"code","metadata":{"id":"GFgyYb1Of58Y","colab_type":"code","colab":{}},"source":["pd.get_dummies(census_data['workclass'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eqHZkWdMhKDL","colab_type":"text"},"source":["What should we do with the question marks?\n","\n","There are a number of techniques available:\n","\n","\n","*   Remove the rows altogether\n","*   Assign a default value\n","*   Assign an average value\n","*   Work out a realistic value for each row\n","\n","\n","**Consider the advantages and disadvantages of each approach**\n"]},{"cell_type":"markdown","metadata":{"id":"RAYd7GuM986d","colab_type":"text"},"source":["For this exercise we will choose the second option and assign a default value of 'Unknown-Workclass'. Then check that it has worked by outputting a summary again. You should see that '?' has been replaced."]},{"cell_type":"code","metadata":{"id":"fbxx6Z3R_XGC","colab_type":"code","colab":{}},"source":["census_data.loc[(census_data['workclass'].str.contains('\\?')), 'workclass'] = 'Unknown-Workclass'\n","census_data.groupby(by=['workclass']).size()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TUCIjfvyQLdJ","colab_type":"text"},"source":["Now we can return to creating 'one hot encodings'. First off all we save the new columns into a variable called new_columns. Then we drop the 'workclass' column from the census data table. When you run this it will output a few rows as before. Note that the number of columns has reduced by one."]},{"cell_type":"code","metadata":{"id":"143DT6ZOQVKi","colab_type":"code","colab":{}},"source":["new_columns = pd.get_dummies(census_data['workclass'])\n","census_data = census_data.drop(['workclass'], axis=1)\n","census_data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TpmoTbBMTTKX","colab_type":"text"},"source":["Now we will add our new columns into the table. There are now 23 columns in the table.\n","\n","**Try and repeat this process for one other column which had question marks in it**"]},{"cell_type":"code","metadata":{"id":"lcFAiU_jTWXm","colab_type":"code","colab":{}},"source":["census_data = census_data.join(new_columns)\n","census_data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vbBcMSPbV_Mj","colab_type":"text"},"source":["Now we return to the education columns. Often preparing data for Machine Learning is about making choices. Since 'education' and 'educationnum' are different representations of the same thing we would only want to use one of them in our ML pipeline.\n","\n","If we decide to use 'educationnum' then we will need to use the technique just learned to turn it into columns. However, if we choose to use 'education' it is already a numeric value. It is worth quickly reviewing the values though just to make sure it makes sense as a number and not a category. There are two aspects you may want to think about:\n","\n","\n","*   Does the order make sense? e.g. Is 12 better than 11?\n","*   Is there a consistent scale? Is 8 twice as good as 4?\n","\n","When we come to Machine Learning with this data we will try both options and see which works best. It may not make much difference but we will see. A lot of ML is about experimentation, trying different options until you find the model that works best.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"58-HvnMpTeXD","colab_type":"text"},"source":["That's the end of this tutorial which aimed to build on the ideas of the first one. As a recap we:\n","\n","\n","*   Worked with data which was a mix of numeric and categorical data\n","*   Used Quartiles to understand the spread of numeric data\n","\n","*   Created summary counts using groupby\n","*   Used a pairs plot to compare numerical columns\n","\n","*   Looked at strategies for dealing with missing data\n","*   Used one hot encoding to turn categories into binary columns\n","\n","\n","\n","\n","\n","\n","\n","\n"]}]}